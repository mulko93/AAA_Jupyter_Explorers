{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output=os.path.join(os.getcwd(), \"..\", \"data\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(os.path.join(path_output, \"Features.csv\"))\n",
    "features = features.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Params from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(os.path.join(os.getcwd(), \"..\", \"data\", \"input\", \"params.csv\")).drop(\"0\", axis=1)\n",
    "_test_size = params[params[\"param\"]==\"test_size\"][\"value\"].values[0]\n",
    "_random_state = int(params[params[\"param\"]==\"random_state\"][\"value\"].values[0])\n",
    "_epochs = int(params[params[\"param\"]==\"epochs\"][\"value\"].values[0])\n",
    "_validation_size = params[params[\"param\"]==\"validation_size\"][\"value\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_support_vector_machine(X_train_scaled, y_train, time_res, hex_size, kernel):\n",
    "    \"\"\"\n",
    "    Train SVM\n",
    "\n",
    "    Train and save an SVM model.\n",
    "    Then evaluate the error metrics by another method.\n",
    "\n",
    "    Args:\n",
    "        X_train_scaled (DataFrame):   Scaled X input of train set (matrix)\n",
    "        y_train (Series):             y output to train on (vector)\n",
    "    Returns:\n",
    "        svm_regression_sets (array): true y values and predicted y values for train and validation set\n",
    "    \"\"\"\n",
    "    # create a validation set which is 20% of the whole dataset. Therefore use formula to receive ca. 0.2857.\n",
    "    # print(\"Splitting train test data...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, random_state=_random_state, test_size=_validation_size)\n",
    "\n",
    "    # print(\"Initializing SVR...\")\n",
    "    svr = make_pipeline(StandardScaler(), SVR(kernel=kernel, cache_size=2000, max_iter=1000))\n",
    "    # svr = SVR(kernel=kernel, max_iter=1000)\n",
    "    # print(svr)\n",
    "    # print(\"Fitting SVR...\")\n",
    "    svr.fit(X_train, y_train)\n",
    "    print(\"Score (Train):\", svr.score(X_train, y_train))\n",
    "    \n",
    "    # create a validation set which is 20% of the whole dataset. Therefore use formula to receive ca. 0.2857.\n",
    "    # print(\"Saving SVR model...\")\n",
    "    filename = \"SVR_model_\"+time_res+\"_\"+hex_size+\"_\"+kernel+\".pkl\"\n",
    "    pickle.dump(svr, open(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"models\", filename), \"wb\"))\n",
    "    \n",
    "    # print(\"Predicting y with train data...\")\n",
    "    y_prediction_train = svr.predict(X_train)\n",
    "    # print(\"Predicting y with validation data...\")\n",
    "    y_prediction_val = svr.predict(X_val)\n",
    "    \n",
    "    # Evaluate Model\n",
    "    # print(confusion_matrix(y_train,y_prediction_train_lin))\n",
    "    # print(classification_report(y_train,y_prediction_train_lin))\n",
    "    # print(confusion_matrix(y_val,y_prediction_val_lin))\n",
    "    # print(classification_report(y_val,y_prediction_val_lin))\n",
    "    \n",
    "    svm_regression_sets = [y_train, y_val, y_prediction_train, y_prediction_val]\n",
    "    return svm_regression_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss(svm_regression_sets, time_res, hex_size, kernel):\n",
    "    \"\"\"\n",
    "    Plot the train and validation loss of Support Vector Machine.\n",
    "\n",
    "    Args:\n",
    "        history (Object): History of loss during training of support vector machine\n",
    "        time_res (str): time resolution to train on\n",
    "    Returns:\n",
    "        No return\n",
    "    \"\"\"\n",
    "    print(\"Plot difference between Train and Predicted Train...\")\n",
    "    y_train = svm_regression_sets[0]\n",
    "    y_val = svm_regression_sets[1]\n",
    "    y_prediction_train = svm_regression_sets[2]\n",
    "    y_prediction_val = svm_regression_sets[3]\n",
    "    \n",
    "    \n",
    "    mae_train = mean_absolute_error(y_train, y_prediction_train)\n",
    "    mae_val = mean_absolute_error(y_val, y_prediction_val)\n",
    "    mse_train = mean_squared_error(y_train, y_prediction_train)\n",
    "    mse_val = mean_squared_error(y_val, y_prediction_val)\n",
    "    r2_train = r2_score(y_train, y_prediction_train)\n",
    "    r2_val = r2_score(y_val, y_prediction_val)\n",
    "    \n",
    "    print()\n",
    "    print(\"=== TRAIN ===\")\n",
    "    print(\"MAE:\", mae_train)\n",
    "    print(\"MSE:\", mse_train)\n",
    "    print(\"R2:\", r2_train)\n",
    "    print()\n",
    "    \n",
    "    print(\"=== VALIDATION ===\")\n",
    "    print(\"MAE:\", mae_val)\n",
    "    print(\"MSE:\", mse_val)\n",
    "    print(\"R2:\", r2_val)\n",
    "    print()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 8), dpi=300)\n",
    "    \n",
    "    ax1.plot(y_prediction_train, y_train, \"bo\")\n",
    "    ax1.set_title(\"Train Y vs Predicted Train Y (\"+time_res+\", \"+hex_size+\", \"+kernel+\")\", fontsize=20)\n",
    "    ax1.set_xlabel(\"Predicted Train Y\", fontsize=18)\n",
    "    ax1.set_ylabel(\"Train Y\", fontsize=18)\n",
    "    \n",
    "    ax2.plot(y_prediction_val, y_val, \"bo\")\n",
    "    ax2.set_title(\"Validation Y vs Predicted Validation Y (\"+time_res+\", \"+hex_size+\", \"+kernel+\")\", fontsize=20)\n",
    "    ax2.set_xlabel(\"Predicted Validation Y\", fontsize=18)\n",
    "    ax2.set_ylabel(\"Validation Y\", fontsize=18)\n",
    "    \n",
    "    fig.savefig(os.path.join(path_output, \"SVM_Train_Validation_Real_vs_Predicted_\"+time_res+\"_\"+hex_size+\"_\"+kernel+\".png\"))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(\"Plot training and visualization loss...\")\n",
    "    \n",
    "    # Plotting the training and validation loss\n",
    "    # loss = history.history[\"loss\"]\n",
    "    # val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    # epochs = range(1, len(loss) + 1)\n",
    "    # fig, ax = plt.subplots(figsize=(16, 8), dpi=300)\n",
    "    # ax.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    # ax.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    # ax.set_title(\"Training and validation loss \"+time_res+\"_\"+hex_size, fontsize=18)\n",
    "    # ax.set_xlabel(\"Epochs\", fontsize=16)\n",
    "    # ax.set_ylabel(\"Loss\", fontsize=16)\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    # fig.savefig(os.path.join(path_output, \"SVM_error_per_epoch_\"+time_res+\"_\"+hex_size+\".png\"))\n",
    "    # plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(time_res=\"24_demand\", hex_size=\"hexa_big\", kernel=\"linear\"):\n",
    "    \"\"\"\n",
    "    Split the data in train and test set by 0.3 test set. \n",
    "    Then Scale the data and do a PCA. \n",
    "    Last train the SVM on the chosen time resolution\n",
    "    \n",
    "    Args:\n",
    "        time_res (str): time resolution to train on\n",
    "        \n",
    "    Returns:\n",
    "        No return\n",
    "    \"\"\"\n",
    "    print(\"Time Resolution is\", time_res)\n",
    "    #print(\"Split Data with random state\", _random_state, \"and test size\", str(_test_size)+\"...\")\n",
    "    # features_X = features.drop([\"24_sum\", \"6_sum\", \"2_sum\", \"1_sum\"], axis=1)\n",
    "    features_X = features.drop([\"24_demand\", \"24_demand_hex_big\", \"24_demand_hex_small\", \"24_agg_time\",\n",
    "                                \"6_demand\", \"6_demand_hex_big\", \"6_demand_hex_small\", \"6_agg_time\",\n",
    "                                \"2_demand\", \"2_demand_hex_big\", \"2_demand_hex_small\", \"2_agg_time\",\n",
    "                                \"1_demand\", \"1_demand_hex_big\", \"1_demand_hex_small\", \"1_agg_time\",\n",
    "                                \"24_available_hex_big\"], axis=1)\n",
    "    features_y = features[time_res]\n",
    "    \n",
    "    # Spatial Resolution\n",
    "    print(\"Spatial Resolution is\", hex_size)\n",
    "    if hex_size==\"hexa_small\":\n",
    "        features_X = features_X.drop(\"hexa_big\", axis=1)\n",
    "    else:\n",
    "        features_X = features_X.drop(\"hexa_small\", axis=1)\n",
    "    \n",
    "    # Kernel\n",
    "    print(\"Kernel is\", kernel)\n",
    "    \n",
    "    #Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_X, features_y, random_state=_random_state, test_size=_test_size)\n",
    "\n",
    "    #print(\"Scale\", hex_size, \"Data with Standard Scaler...\")\n",
    "    with open(os.path.join(path_output, \"models\", \"Standard_Scaler_\"+hex_size+\".pkl\"), \"rb\") as f:\n",
    "        standard_scaler = pickle.load(f)\n",
    "    X_train_scaled = standard_scaler.transform(X_train)\n",
    "\n",
    "    print(\"Do PCA on\", hex_size, \"Data...\")\n",
    "    with open(os.path.join(path_output, \"models\", \"PCA_\"+hex_size+\".pkl\"), \"rb\") as f:\n",
    "        pca = pickle.load(f)\n",
    "    X_train_transformed = pca.transform(X_train_scaled)\n",
    "    \n",
    "    # PCA\n",
    "    # pca = PCA(n_components=10)\n",
    "    # pca.fit(X_train_scaled)\n",
    "    # pca_explained_variance = pca.explained_variance_ratio_\n",
    "    #  print(\"Var explained:\", pca_explained_variance)\n",
    "    # print(\"Sum var explained\", sum(pca_explained_variance))\n",
    "    # X_train_transformed = pca.transform(X_train_scaled)\n",
    "    # print(\"X_train_transformed:\", X_train_transformed)\n",
    "\n",
    "    print(\"Train\", \"SVM_Regression_Model_\"+time_res+\"_\"+hex_size+\"_\"+kernel, \"...\")\n",
    "    svm_regression_sets = train_support_vector_machine(X_train_transformed, y_train.to_numpy(), time_res=time_res, hex_size=hex_size, kernel=kernel)\n",
    "    plot_train_loss(svm_regression_sets, time_res=time_res, hex_size=hex_size, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is linear\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_big_linear ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -0.28315578750727877\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 1109.5313708621782\n",
      "MSE: 3007555.465012589\n",
      "R2: -0.28315578750727877\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 1108.6876790385004\n",
      "MSE: 2989228.991416422\n",
      "R2: -0.2860404644788419\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is rbf\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_big_rbf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -1.9323751392781046\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 2524.181723707827\n",
      "MSE: 6873117.794009784\n",
      "R2: -1.9323751392781046\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 2523.585386589764\n",
      "MSE: 6870064.215466413\n",
      "R2: -1.9556720478853031\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is poly\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_big_poly ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -1704.26937166041\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 63202.54224961015\n",
      "MSE: 3996936512.299179\n",
      "R2: -1704.26937166041\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 63198.5465897708\n",
      "MSE: 3996407542.530379\n",
      "R2: -1718.3536617638597\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is sigmoid\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_big_sigmoid ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -1.7498400437317936\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 2435.7697748050327\n",
      "MSE: 6445278.5327822855\n",
      "R2: -1.7498400437317936\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 2434.8031216068307\n",
      "MSE: 6440409.197483393\n",
      "R2: -1.7708238009028179\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is linear\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_small_linear ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -0.24664579300744105\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 1085.2230797242014\n",
      "MSE: 2921980.638826533\n",
      "R2: -0.24664579300744105\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 1084.5594259504387\n",
      "MSE: 2904578.689021077\n",
      "R2: -0.2496218045088674\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is rbf\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_small_rbf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -1.9365876183655004\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 2526.1437261700776\n",
      "MSE: 6882991.314141864\n",
      "R2: -1.9365876183655004\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 2525.5525782586546\n",
      "MSE: 6879974.381906166\n",
      "R2: -1.9599356473244356\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is poly\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_small_poly ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -6178.769810871635\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 120342.1076027446\n",
      "MSE: 14484601673.591694\n",
      "R2: -6178.769810871635\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 120338.19756233272\n",
      "MSE: 14483675044.75448\n",
      "R2: -6230.236293841309\n",
      "\n",
      "\n",
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is sigmoid\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_24_demand_hexa_small_sigmoid ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -1.762184938324466\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 2441.973587123943\n",
      "MSE: 6474213.410026867\n",
      "R2: -1.762184938324466\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 2440.9960076489183\n",
      "MSE: 6469267.364646423\n",
      "R2: -1.78323930028708\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is linear\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_big_linear ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -1.637434830448778\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 493.2429946895971\n",
      "MSE: 290140.791303586\n",
      "R2: -1.637434830448778\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 492.2920728225054\n",
      "MSE: 289043.12508448376\n",
      "R2: -1.6930513529398281\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is rbf\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_big_rbf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -8.535099669548687\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 998.8568096444498\n",
      "MSE: 1048943.9706120337\n",
      "R2: -8.535099669548687\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 999.5605501367028\n",
      "MSE: 1049786.5014599457\n",
      "R2: -8.780993605118061\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is poly\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_big_poly ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -706.7755224750874\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 8817.65909118935\n",
      "MSE: 77861468.94908807\n",
      "R2: -706.7755224750874\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 8815.951337531496\n",
      "MSE: 77828573.52706856\n",
      "R2: -724.1386628662641\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is sigmoid\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_big_sigmoid ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -7.521325621265364\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 942.9436919631142\n",
      "MSE: 937419.9999811031\n",
      "R2: -7.521325621265364\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 943.567266415397\n",
      "MSE: 938131.2331199656\n",
      "R2: -7.740687348472262\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is linear\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_small_linear ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -4.605511712869355\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 755.9249770015424\n",
      "MSE: 616655.0866990305\n",
      "R2: -4.605511712869355\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 756.1216053224015\n",
      "MSE: 616615.5036049298\n",
      "R2: -4.745084633102978\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is rbf\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_small_rbf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -8.558648355003097\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 1000.1040503361559\n",
      "MSE: 1051534.5310130045\n",
      "R2: -8.558648355003097\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 1000.8099662913477\n",
      "MSE: 1052380.7582011865\n",
      "R2: -8.805164623283016\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is poly\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_small_poly ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -458.87463420959585\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 7104.930862387642\n",
      "MSE: 50590213.16076102\n",
      "R2: -458.87463420959585\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 7103.208320780201\n",
      "MSE: 50563078.36117588\n",
      "R2: -470.1025960211533\n",
      "\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Kernel is sigmoid\n",
      "Do PCA on hexa_small Data...\n",
      "Train SVM_Regression_Model_1_demand_hexa_small_sigmoid ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -7.546711977675004\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 944.3860188065182\n",
      "MSE: 940212.7201848303\n",
      "R2: -7.546711977675004\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 945.0187080810281\n",
      "MSE: 940941.0945573403\n",
      "R2: -7.7668671828595475\n",
      "\n",
      "\n",
      "Time Resolution is 24_available_hex_big\n",
      "Spatial Resolution is hexa_big\n",
      "Kernel is linear\n",
      "Do PCA on hexa_big Data...\n",
      "Train SVM_Regression_Model_24_available_hex_big_hexa_big_linear ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Train): -17.12848878500209\n",
      "Plot difference between Train and Predicted Train...\n",
      "\n",
      "=== TRAIN ===\n",
      "MAE: 584.8133312614224\n",
      "MSE: 362175.5498883341\n",
      "R2: -17.12848878500209\n",
      "\n",
      "=== VALIDATION ===\n",
      "MAE: 584.9035838597853\n",
      "MSE: 362293.6440177584\n",
      "R2: -17.129510750473653\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Train the SVM for each time resolution.\n",
    "hex_size = [\"hexa_big\", \"hexa_small\"]\n",
    "time_resolutions = [\"24_demand\", \"1_demand\"]\n",
    "kernels = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
    "\n",
    "# \"\"\"\n",
    "for time in time_resolutions:\n",
    "    for size in hex_size:\n",
    "        for kernel in kernels:\n",
    "            train_SVM(time_res=time, hex_size=size, kernel=kernel)\n",
    "            print()\n",
    "# \"\"\"\n",
    "\n",
    "train_SVM(time_res=\"24_available_hex_big\", hex_size=\"hexa_big\", kernel=\"linear\")\n",
    "# train_SVM(time_res=\"24_demand\", hex_size=\"hexa_big\", kernel=\"sigmoid\")\n",
    "# train_SVM(time_res=\"24_demand\", hex_size=\"hexa_big\", kernel=\"precomputed\")\n",
    "# train_SVM(time_res=\"24_sum\", hex_size=\"hexa_big\", kernel=\"rbf\")\n",
    "# train_SVM(time_res=\"24_sum\", hex_size=\"hexa_big\", kernel=\"poly\")\n",
    "# train_SVM(time_res=\"1_sum\", hex_size=\"hexa_small\", kernel=\"linear\")\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
