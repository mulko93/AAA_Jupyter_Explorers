{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature preparation\n",
    "Right here the features for the ml models are created and filtered. Then a csv with only the important features is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Documents\\GitHub\\AAA_Jupyter_Explorers\\notebooks\\..\\data\\output\\Trips_Hexagons.csv\n"
     ]
    }
   ],
   "source": [
    "path_trips_hexagons=os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"Trips_Hexagons.csv\")\n",
    "path_hexagons=os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"hexagons-dresden.csv\")\n",
    "path_trips = os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"Trips.csv\")\n",
    "print(path_trips_hexagons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>p_bike_racks_start</th>\n",
       "      <th>p_spot_start</th>\n",
       "      <th>p_booked_bikes_start</th>\n",
       "      <th>p_place_type_start</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>b_number_start</th>\n",
       "      <th>p_uid_start</th>\n",
       "      <th>p_bikes_start</th>\n",
       "      <th>p_lat_start</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>24_sum</th>\n",
       "      <th>6_sum</th>\n",
       "      <th>2_sum</th>\n",
       "      <th>1_sum</th>\n",
       "      <th>h3_hex_small_id_start</th>\n",
       "      <th>h3_hex_small_id_end</th>\n",
       "      <th>h3_hex_big_id_start</th>\n",
       "      <th>h3_hex_big_id_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>93771</td>\n",
       "      <td>12095573</td>\n",
       "      <td>1</td>\n",
       "      <td>51.071262</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>871f1b54bffffff</td>\n",
       "      <td>871f1b559ffffff</td>\n",
       "      <td>861f1b54fffffff</td>\n",
       "      <td>861f1b55fffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-20 00:05:00</td>\n",
       "      <td>93576</td>\n",
       "      <td>10299640</td>\n",
       "      <td>5</td>\n",
       "      <td>51.038210</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>871f1b460ffffff</td>\n",
       "      <td>871f1b464ffffff</td>\n",
       "      <td>861f1b467ffffff</td>\n",
       "      <td>861f1b467ffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-20 00:07:00</td>\n",
       "      <td>93440</td>\n",
       "      <td>10299584</td>\n",
       "      <td>1</td>\n",
       "      <td>51.042570</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>871f1b559ffffff</td>\n",
       "      <td>871f1b460ffffff</td>\n",
       "      <td>861f1b55fffffff</td>\n",
       "      <td>861f1b467ffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-20 00:07:00</td>\n",
       "      <td>93322</td>\n",
       "      <td>12098234</td>\n",
       "      <td>1</td>\n",
       "      <td>51.041798</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>871f1b559ffffff</td>\n",
       "      <td>871f1b559ffffff</td>\n",
       "      <td>861f1b55fffffff</td>\n",
       "      <td>861f1b55fffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-20 00:07:00</td>\n",
       "      <td>93585</td>\n",
       "      <td>264575</td>\n",
       "      <td>5</td>\n",
       "      <td>51.071740</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>871f1b54bffffff</td>\n",
       "      <td>871f1b54bffffff</td>\n",
       "      <td>861f1b54fffffff</td>\n",
       "      <td>861f1b54fffffff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  p_bike_racks_start  p_spot_start  p_booked_bikes_start  \\\n",
       "0           0                   0         False                     0   \n",
       "1           1                   0          True                     0   \n",
       "2           2                   0          True                     0   \n",
       "3           3                   0         False                     0   \n",
       "4           4                   0          True                     0   \n",
       "\n",
       "   p_place_type_start       datetime_start  b_number_start  p_uid_start  \\\n",
       "0                  12  2019-01-20 00:00:00           93771     12095573   \n",
       "1                   0  2019-01-20 00:05:00           93576     10299640   \n",
       "2                   0  2019-01-20 00:07:00           93440     10299584   \n",
       "3                  12  2019-01-20 00:07:00           93322     12098234   \n",
       "4                   0  2019-01-20 00:07:00           93585       264575   \n",
       "\n",
       "   p_bikes_start  p_lat_start  ...  trip_duration  idle_time 24_sum  6_sum  \\\n",
       "0              1    51.071262  ...           28.0        0.0    265     36   \n",
       "1              5    51.038210  ...           10.0        0.0    265     33   \n",
       "2              1    51.042570  ...           26.0        0.0    265     33   \n",
       "3              1    51.041798  ...            2.0        0.0    265     33   \n",
       "4              5    51.071740  ...           28.0        0.0    265     33   \n",
       "\n",
       "  2_sum  1_sum  h3_hex_small_id_start  h3_hex_small_id_end  \\\n",
       "0    19      8        871f1b54bffffff      871f1b559ffffff   \n",
       "1    17     17        871f1b460ffffff      871f1b464ffffff   \n",
       "2    17     17        871f1b559ffffff      871f1b460ffffff   \n",
       "3    17     17        871f1b559ffffff      871f1b559ffffff   \n",
       "4    17     17        871f1b54bffffff      871f1b54bffffff   \n",
       "\n",
       "   h3_hex_big_id_start  h3_hex_big_id_end  \n",
       "0      861f1b54fffffff    861f1b55fffffff  \n",
       "1      861f1b467ffffff    861f1b467ffffff  \n",
       "2      861f1b55fffffff    861f1b467ffffff  \n",
       "3      861f1b55fffffff    861f1b55fffffff  \n",
       "4      861f1b54fffffff    861f1b54fffffff  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_trips)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 567439 entries, 0 to 567438\n",
      "Data columns (total 61 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Unnamed: 0             567439 non-null  int64  \n",
      " 1   p_bike_racks_start     567439 non-null  int64  \n",
      " 2   p_spot_start           567439 non-null  bool   \n",
      " 3   p_booked_bikes_start   567439 non-null  int64  \n",
      " 4   p_place_type_start     567439 non-null  int64  \n",
      " 5   datetime_start         567439 non-null  object \n",
      " 6   b_number_start         567439 non-null  int64  \n",
      " 7   p_uid_start            567439 non-null  int64  \n",
      " 8   p_bikes_start          567439 non-null  int64  \n",
      " 9   p_lat_start            567439 non-null  float64\n",
      " 10  b_electric_lock_start  567439 non-null  bool   \n",
      " 11  b_bike_type_start      567439 non-null  int64  \n",
      " 12  p_name_start           567439 non-null  object \n",
      " 13  p_free_racks_start     567439 non-null  int64  \n",
      " 14  b_lock_types_start     567439 non-null  object \n",
      " 15  p_number_start         567377 non-null  float64\n",
      " 16  p_lng_start            567439 non-null  float64\n",
      " 17  b_boardcomputer_start  567439 non-null  int64  \n",
      " 18  p_maintenance_start    567439 non-null  bool   \n",
      " 19  p_bike_racks_end       567439 non-null  int64  \n",
      " 20  p_spot_end             567439 non-null  bool   \n",
      " 21  p_booked_bikes_end     567439 non-null  int64  \n",
      " 22  p_place_type_end       567439 non-null  int64  \n",
      " 23  datetime_end           567439 non-null  object \n",
      " 24  p_uid_end              567439 non-null  int64  \n",
      " 25  p_bikes_end            567439 non-null  int64  \n",
      " 26  p_lat_end              567439 non-null  float64\n",
      " 27  p_name_end             567439 non-null  object \n",
      " 28  p_free_racks_end       567439 non-null  int64  \n",
      " 29  p_number_end           567361 non-null  float64\n",
      " 30  p_lng_end              567439 non-null  float64\n",
      " 31  p_maintenance_end      567439 non-null  bool   \n",
      " 32  air_deg                567439 non-null  float64\n",
      " 33  air_hum                567439 non-null  float64\n",
      " 34  rain_mm                567439 non-null  float64\n",
      " 35  rain_yn                567439 non-null  float64\n",
      " 36  sun_hour               567439 non-null  float64\n",
      " 37  wind_ms                567439 non-null  float64\n",
      " 38  month_start            567439 non-null  int64  \n",
      " 39  month_end              567439 non-null  int64  \n",
      " 40  day_start              567439 non-null  int64  \n",
      " 41  day_end                567439 non-null  int64  \n",
      " 42  day_of_week_start      567439 non-null  int64  \n",
      " 43  day_of_week_end        567439 non-null  int64  \n",
      " 44  hour_start             567439 non-null  int64  \n",
      " 45  hour_end               567439 non-null  int64  \n",
      " 46  day_of_year_start      567439 non-null  int64  \n",
      " 47  day_of_year_end        567439 non-null  int64  \n",
      " 48  season                 567439 non-null  int64  \n",
      " 49  weekend                567439 non-null  bool   \n",
      " 50  booking_date_start     567439 non-null  object \n",
      " 51  trip_duration          567439 non-null  float64\n",
      " 52  idle_time              567439 non-null  float64\n",
      " 53  24_sum                 567439 non-null  int64  \n",
      " 54  6_sum                  567439 non-null  int64  \n",
      " 55  2_sum                  567439 non-null  int64  \n",
      " 56  1_sum                  567439 non-null  int64  \n",
      " 57  h3_hex_small_id_start  567439 non-null  object \n",
      " 58  h3_hex_small_id_end    567439 non-null  object \n",
      " 59  h3_hex_big_id_start    567439 non-null  object \n",
      " 60  h3_hex_big_id_end      567439 non-null  object \n",
      "dtypes: bool(6), float64(14), int64(31), object(10)\n",
      "memory usage: 241.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               0\n",
       "p_bike_racks_start       0\n",
       "p_spot_start             0\n",
       "p_booked_bikes_start     0\n",
       "p_place_type_start       0\n",
       "                        ..\n",
       "1_sum                    0\n",
       "h3_hex_small_id_start    0\n",
       "h3_hex_small_id_end      0\n",
       "h3_hex_big_id_start      0\n",
       "h3_hex_big_id_end        0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop not needed columns\n",
    "Drop end information and not usefull columns.\n",
    "The features are cleaned in three steps. <br>\n",
    "- features_1 => drop not usefull columns \n",
    "- features_2 => drop end information\n",
    "- features_3 => drop object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop not int columns and not usefull\n",
      "Drop end information\n",
      "Drop object types...\n"
     ]
    }
   ],
   "source": [
    "print(\"Drop not int columns and not usefull\")\n",
    "# Unnamed: 0 => index column\n",
    "# p_terminal_type_end => NaN values\n",
    "features_1 = df.drop([\"Unnamed: 0\", \n",
    "                      #\"p_terminal_type_start\", \n",
    "                      \"p_number_start\", \n",
    "                      #\"b_pedelec_battery_start\"\n",
    "                     ], axis=1)\n",
    "print(\"Drop end information\")\n",
    "features_2 = features_1.drop(\n",
    "    [\"p_bike_racks_end\",\n",
    "     \"p_spot_end\", \n",
    "     \"p_booked_bikes_end\", \n",
    "     \"p_place_type_end\", \n",
    "     \"datetime_end\",\n",
    "     \"p_uid_end\",\n",
    "     \"p_bikes_end\",     \n",
    "     \"p_lat_end\",\n",
    "     \"p_name_end\",\n",
    "     \"p_free_racks_end\",\n",
    "     #\"p_address_end\",\n",
    "     \"p_number_end\",\n",
    "     \"p_lng_end\",\n",
    "     \"p_maintenance_end\",\n",
    "     \"h3_hex_small_id_end\",\n",
    "     \"h3_hex_big_id_end\",\n",
    "     \"trip_duration\"\n",
    "     #\"p_terminal_type_end\", \n",
    "     #\"p_bike_types_end\"\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "print(\"Drop object types...\")\n",
    "features_3 = features_2.drop([\"datetime_start\", \n",
    "                              \"p_name_start\", \n",
    "                              #\"p_address_start\", \n",
    "                              \"b_lock_types_start\",\n",
    "                              \"booking_date_start\",\n",
    "                              #\"p_bike_types_start\", \n",
    "                              #\"MESS_DATUM\"\n",
    "                             ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy\n",
    "Create Dummy variables for all booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spot_start = features_3[\"p_spot_start\"].astype(int)\n",
    "b_electric_lock_start = features_3[\"b_electric_lock_start\"].astype(int)\n",
    "p_maintenance_start = features_3[\"p_maintenance_start\"].astype(int)\n",
    "weekend = features_3[\"weekend\"].astype(int)\n",
    "\n",
    "le = LabelEncoder()\n",
    "hexa_small = pd.Series(le.fit_transform(features_3[\"h3_hex_small_id_start\"]))\n",
    "hexa_big = pd.Series(le.fit_transform(features_3[\"h3_hex_big_id_start\"]))\n",
    "\n",
    "# weekend = p_df[\"Weekend\"].astype(int)\n",
    "features = features_3.drop([\"p_spot_start\", \"b_electric_lock_start\", \"p_maintenance_start\", \"weekend\", \"h3_hex_small_id_start\", \"h3_hex_big_id_start\"], axis=1)\n",
    "features = pd.concat([features, p_spot_start, b_electric_lock_start, p_maintenance_start, weekend, hexa_small, hexa_big], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features[\"XYZ\"] = np.square(features[\"XXX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features\n",
    "features.to_csv(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"Features.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_X = features.drop([\"24_sum\", \"6_sum\", \"2_sum\", \"1_sum\"], axis=1)\n",
    "features_y = features[\"24_sum\"] #TODO: make var\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, features_y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD SCALER\n",
    "st_scaler = StandardScaler()\n",
    "# fit scaler only on training set not on test set\n",
    "st_scaler.fit(X_train)\n",
    "\n",
    "# Save Scaler Object\n",
    "obj = st_scaler\n",
    "filename = \"Standard_Scaler.pkl\"\n",
    "pickle.dump(obj, open(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"models\", filename), \"wb\"))\n",
    "\n",
    "X_train_scaled = st_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var explained: [0.15116754 0.09024424 0.07722063 0.07159344 0.06053688 0.05859782\n",
      " 0.05745243 0.05158906 0.05056532 0.04886894 0.03663008 0.03028615\n",
      " 0.0299577  0.02838975 0.02822204 0.0268716  0.01775359 0.01640399\n",
      " 0.01448348 0.01402899]\n",
      "Sum var explained 0.9608636938598711\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=20) # Number of components is set here\n",
    "pca.fit(X_train_scaled)\n",
    "pca_explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Var explained:\", pca_explained_variance)\n",
    "print(\"Sum var explained\", sum(pca_explained_variance))\n",
    "\n",
    "# Save PCA Object\n",
    "obj = pca\n",
    "filename = \"PCA.pkl\"\n",
    "pickle.dump(obj, open(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"models\", filename), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
