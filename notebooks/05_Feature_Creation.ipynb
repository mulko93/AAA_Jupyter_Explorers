{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature preparation\n",
    "Right here the features for the ml models are created and filtered. Then a csv with only the important features is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trips = os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"Trips.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Params from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(os.path.join(os.getcwd(), \"..\", \"data\", \"input\", \"params.csv\")).drop(\"0\", axis=1)\n",
    "_test_size = params[params[\"param\"]==\"test_size\"][\"value\"].values[0]\n",
    "_random_state = int(params[params[\"param\"]==\"random_state\"][\"value\"].values[0])\n",
    "_pca_components = int(params[params[\"param\"]==\"pca_components\"][\"value\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>p_bike_racks_start</th>\n",
       "      <th>p_spot_start</th>\n",
       "      <th>p_booked_bikes_start</th>\n",
       "      <th>p_place_type_start</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>b_number_start</th>\n",
       "      <th>p_uid_start</th>\n",
       "      <th>p_bikes_start</th>\n",
       "      <th>p_lat_start</th>\n",
       "      <th>...</th>\n",
       "      <th>6_demand_hex_small</th>\n",
       "      <th>6_agg_time</th>\n",
       "      <th>2_demand</th>\n",
       "      <th>2_demand_hex_big</th>\n",
       "      <th>2_demand_hex_small</th>\n",
       "      <th>2_agg_time</th>\n",
       "      <th>1_demand</th>\n",
       "      <th>1_demand_hex_big</th>\n",
       "      <th>1_demand_hex_small</th>\n",
       "      <th>1_agg_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>93771</td>\n",
       "      <td>12095573</td>\n",
       "      <td>1</td>\n",
       "      <td>51.071262</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-20 00:05:00</td>\n",
       "      <td>93576</td>\n",
       "      <td>10299640</td>\n",
       "      <td>5</td>\n",
       "      <td>51.038210</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-20 00:07:00</td>\n",
       "      <td>93440</td>\n",
       "      <td>10299584</td>\n",
       "      <td>1</td>\n",
       "      <td>51.042570</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-20 00:07:00</td>\n",
       "      <td>93322</td>\n",
       "      <td>12098234</td>\n",
       "      <td>1</td>\n",
       "      <td>51.041798</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-20 00:07:00</td>\n",
       "      <td>93585</td>\n",
       "      <td>264575</td>\n",
       "      <td>5</td>\n",
       "      <td>51.071740</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  p_bike_racks_start  p_spot_start  p_booked_bikes_start  \\\n",
       "0           0                   0         False                     0   \n",
       "1           1                   0          True                     0   \n",
       "2           2                   0          True                     0   \n",
       "3           3                   0         False                     0   \n",
       "4           4                   0          True                     0   \n",
       "\n",
       "   p_place_type_start       datetime_start  b_number_start  p_uid_start  \\\n",
       "0                  12  2019-01-20 00:00:00           93771     12095573   \n",
       "1                   0  2019-01-20 00:05:00           93576     10299640   \n",
       "2                   0  2019-01-20 00:07:00           93440     10299584   \n",
       "3                  12  2019-01-20 00:07:00           93322     12098234   \n",
       "4                   0  2019-01-20 00:07:00           93585       264575   \n",
       "\n",
       "   p_bikes_start  p_lat_start  ...  6_demand_hex_small           6_agg_time  \\\n",
       "0              1    51.071262  ...                   3  2019-01-20 00:00:00   \n",
       "1              5    51.038210  ...                   2  2019-01-20 00:00:00   \n",
       "2              1    51.042570  ...                   2  2019-01-20 00:00:00   \n",
       "3              1    51.041798  ...                   2  2019-01-20 00:00:00   \n",
       "4              5    51.071740  ...                   2  2019-01-20 00:00:00   \n",
       "\n",
       "  2_demand  2_demand_hex_big 2_demand_hex_small           2_agg_time  \\\n",
       "0       27                 7                  2  2019-01-20 00:00:00   \n",
       "1       27                13                  2  2019-01-20 00:00:00   \n",
       "2       27                 5                  2  2019-01-20 00:00:00   \n",
       "3       27                 5                  2  2019-01-20 00:00:00   \n",
       "4       27                 7                  2  2019-01-20 00:00:00   \n",
       "\n",
       "   1_demand  1_demand_hex_big  1_demand_hex_small           1_agg_time  \n",
       "0        19                 5                   2  2019-01-20 00:00:00  \n",
       "1        19                 8                   2  2019-01-20 00:00:00  \n",
       "2        19                 5                   2  2019-01-20 00:00:00  \n",
       "3        19                 5                   2  2019-01-20 00:00:00  \n",
       "4        19                 5                   2  2019-01-20 00:00:00  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_trips)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 567439 entries, 0 to 567438\n",
      "Data columns (total 73 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Unnamed: 0             567439 non-null  int64  \n",
      " 1   p_bike_racks_start     567439 non-null  int64  \n",
      " 2   p_spot_start           567439 non-null  bool   \n",
      " 3   p_booked_bikes_start   567439 non-null  int64  \n",
      " 4   p_place_type_start     567439 non-null  int64  \n",
      " 5   datetime_start         567439 non-null  object \n",
      " 6   b_number_start         567439 non-null  int64  \n",
      " 7   p_uid_start            567439 non-null  int64  \n",
      " 8   p_bikes_start          567439 non-null  int64  \n",
      " 9   p_lat_start            567439 non-null  float64\n",
      " 10  b_electric_lock_start  567439 non-null  bool   \n",
      " 11  b_bike_type_start      567439 non-null  int64  \n",
      " 12  p_name_start           567439 non-null  object \n",
      " 13  p_free_racks_start     567439 non-null  int64  \n",
      " 14  b_lock_types_start     567439 non-null  object \n",
      " 15  p_number_start         567377 non-null  float64\n",
      " 16  p_lng_start            567439 non-null  float64\n",
      " 17  b_boardcomputer_start  567439 non-null  int64  \n",
      " 18  p_maintenance_start    567439 non-null  bool   \n",
      " 19  p_bike_racks_end       567439 non-null  int64  \n",
      " 20  p_spot_end             567439 non-null  bool   \n",
      " 21  p_booked_bikes_end     567439 non-null  int64  \n",
      " 22  p_place_type_end       567439 non-null  int64  \n",
      " 23  datetime_end           567439 non-null  object \n",
      " 24  p_uid_end              567439 non-null  int64  \n",
      " 25  p_bikes_end            567439 non-null  int64  \n",
      " 26  p_lat_end              567439 non-null  float64\n",
      " 27  p_name_end             567439 non-null  object \n",
      " 28  p_free_racks_end       567439 non-null  int64  \n",
      " 29  p_number_end           567361 non-null  float64\n",
      " 30  p_lng_end              567439 non-null  float64\n",
      " 31  p_maintenance_end      567439 non-null  bool   \n",
      " 32  air_deg                567439 non-null  float64\n",
      " 33  air_hum                567439 non-null  float64\n",
      " 34  rain_mm                567439 non-null  float64\n",
      " 35  rain_yn                567439 non-null  float64\n",
      " 36  sun_hour               567439 non-null  float64\n",
      " 37  wind_ms                567439 non-null  float64\n",
      " 38  month_start            567439 non-null  int64  \n",
      " 39  month_end              567439 non-null  int64  \n",
      " 40  day_start              567439 non-null  int64  \n",
      " 41  day_end                567439 non-null  int64  \n",
      " 42  day_of_week_start      567439 non-null  int64  \n",
      " 43  day_of_week_end        567439 non-null  int64  \n",
      " 44  hour_start             567439 non-null  int64  \n",
      " 45  hour_end               567439 non-null  int64  \n",
      " 46  day_of_year_start      567439 non-null  int64  \n",
      " 47  day_of_year_end        567439 non-null  int64  \n",
      " 48  season                 567439 non-null  int64  \n",
      " 49  weekend                567439 non-null  bool   \n",
      " 50  booking_date_start     567439 non-null  object \n",
      " 51  trip_duration          567439 non-null  float64\n",
      " 52  idle_time              567439 non-null  float64\n",
      " 53  h3_hex_small_id_start  567439 non-null  object \n",
      " 54  h3_hex_small_id_end    567439 non-null  object \n",
      " 55  h3_hex_big_id_start    567439 non-null  object \n",
      " 56  h3_hex_big_id_end      567439 non-null  object \n",
      " 57  24_demand              567439 non-null  int64  \n",
      " 58  24_demand_hex_big      567439 non-null  int64  \n",
      " 59  24_demand_hex_small    567439 non-null  int64  \n",
      " 60  24_agg_time            567439 non-null  object \n",
      " 61  6_demand               567439 non-null  int64  \n",
      " 62  6_demand_hex_big       567439 non-null  int64  \n",
      " 63  6_demand_hex_small     567439 non-null  int64  \n",
      " 64  6_agg_time             567439 non-null  object \n",
      " 65  2_demand               567439 non-null  int64  \n",
      " 66  2_demand_hex_big       567439 non-null  int64  \n",
      " 67  2_demand_hex_small     567439 non-null  int64  \n",
      " 68  2_agg_time             567439 non-null  object \n",
      " 69  1_demand               567439 non-null  int64  \n",
      " 70  1_demand_hex_big       567439 non-null  int64  \n",
      " 71  1_demand_hex_small     567439 non-null  int64  \n",
      " 72  1_agg_time             567439 non-null  object \n",
      "dtypes: bool(6), float64(14), int64(39), object(14)\n",
      "memory usage: 293.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "p_bike_racks_start      0\n",
       "p_spot_start            0\n",
       "p_booked_bikes_start    0\n",
       "p_place_type_start      0\n",
       "                       ..\n",
       "2_agg_time              0\n",
       "1_demand                0\n",
       "1_demand_hex_big        0\n",
       "1_demand_hex_small      0\n",
       "1_agg_time              0\n",
       "Length: 73, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop not needed columns\n",
    "Drop end information and not usefull columns.\n",
    "The features are cleaned in three steps. <br>\n",
    "- features_1 => drop not usefull columns \n",
    "- features_2 => drop end information\n",
    "- features_3 => drop object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop not int columns and not usefull\n",
      "Drop end information\n",
      "Drop object types...\n"
     ]
    }
   ],
   "source": [
    "print(\"Drop not int columns and not usefull\")\n",
    "# Unnamed: 0 => index column\n",
    "# p_terminal_type_end => NaN values\n",
    "features_1 = df.drop([\"Unnamed: 0\", \n",
    "                      #\"p_terminal_type_start\", \n",
    "                      \"p_number_start\", \n",
    "                      #\"b_pedelec_battery_start\"\n",
    "                     ], axis=1)\n",
    "print(\"Drop end information\")\n",
    "features_2 = features_1.drop(\n",
    "    [\"p_bike_racks_end\",\n",
    "     \"p_spot_end\", \n",
    "     \"p_booked_bikes_end\", \n",
    "     \"p_place_type_end\", \n",
    "     \"datetime_end\",\n",
    "     \"p_uid_end\",\n",
    "     \"p_bikes_end\",     \n",
    "     \"p_lat_end\",\n",
    "     \"p_name_end\",\n",
    "     \"p_free_racks_end\",\n",
    "     #\"p_address_end\",\n",
    "     \"p_number_end\",\n",
    "     \"p_lng_end\",\n",
    "     \"p_maintenance_end\",\n",
    "     \"h3_hex_small_id_end\",\n",
    "     \"h3_hex_big_id_end\",\n",
    "     \"trip_duration\"\n",
    "     #\"p_terminal_type_end\", \n",
    "     #\"p_bike_types_end\"\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "print(\"Drop object types...\")\n",
    "features_3 = features_2.drop([\"datetime_start\", \n",
    "                              \"p_name_start\", \n",
    "                              #\"p_address_start\", \n",
    "                              \"b_lock_types_start\",\n",
    "                              \"booking_date_start\",\n",
    "                              #\"p_bike_types_start\", \n",
    "                              #\"MESS_DATUM\"\n",
    "                             ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy\n",
    "Create Dummy variables for all booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spot_start = features_3[\"p_spot_start\"].astype(int)\n",
    "b_electric_lock_start = features_3[\"b_electric_lock_start\"].astype(int)\n",
    "p_maintenance_start = features_3[\"p_maintenance_start\"].astype(int)\n",
    "weekend = features_3[\"weekend\"].astype(int)\n",
    "\n",
    "le = LabelEncoder()\n",
    "hexa_small = pd.Series(le.fit_transform(features_3[\"h3_hex_small_id_start\"]))\n",
    "hexa_big = pd.Series(le.fit_transform(features_3[\"h3_hex_big_id_start\"]))\n",
    "\n",
    "# weekend = p_df[\"Weekend\"].astype(int)\n",
    "features = features_3.drop([\"p_spot_start\", \"b_electric_lock_start\", \"p_maintenance_start\", \"weekend\", \"h3_hex_small_id_start\", \"h3_hex_big_id_start\"], axis=1)\n",
    "features = pd.concat([features, p_spot_start, b_electric_lock_start, p_maintenance_start, weekend, hexa_small, hexa_big], axis=1)\n",
    "features = features.rename({0:\"hexa_small\", 1:\"hexa_big\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features[\"XYZ\"] = np.square(features[\"XXX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features\n",
    "features.to_csv(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"Features.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scaler_pca(hex_size=\"hexa_small\"):\n",
    "    \"\"\"\n",
    "    Train Scaler and PCA depending on hex size.\n",
    "    \n",
    "    Args:\n",
    "        hex_size (str): which hex size should be used? small or big possible\n",
    "        \n",
    "    Returns:\n",
    "        No return\n",
    "    \"\"\"\n",
    "    \n",
    "    #FILTER\n",
    "    features_X = features.drop([\"24_demand\", \"24_demand_hex_big\", \"24_demand_hex_small\", \"24_agg_time\",\n",
    "                                \"6_demand\", \"6_demand_hex_big\", \"6_demand_hex_small\", \"6_agg_time\",\n",
    "                                \"2_demand\", \"2_demand_hex_big\", \"2_demand_hex_small\", \"2_agg_time\",\n",
    "                                \"1_demand\", \"1_demand_hex_big\", \"1_demand_hex_small\", \"1_agg_time\"], axis=1)\n",
    "    if hex_size==\"hexa_small\":\n",
    "        features_X = features_X.drop(\"hexa_big\", axis=1)\n",
    "    else:\n",
    "        features_X = features_X.drop(\"hexa_small\", axis=1)\n",
    "    \n",
    "    features_y = features[\"24_demand\"]\n",
    "    \n",
    "    #SPLIT\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_X, features_y, random_state=_random_state, test_size=_test_size)\n",
    "\n",
    "    # STANDARD SCALER\n",
    "    st_scaler = StandardScaler()\n",
    "    # fit scaler only on training set not on test set\n",
    "    st_scaler.fit(X_train)\n",
    "\n",
    "    # Save Scaler Object\n",
    "    obj = st_scaler\n",
    "    filename = \"Standard_Scaler_\"+hex_size+\".pkl\"\n",
    "    pickle.dump(obj, open(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"models\", filename), \"wb\"))\n",
    "    #Scale\n",
    "    X_train_scaled = st_scaler.transform(X_train)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=_pca_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    pca_explained_variance = pca.explained_variance_ratio_\n",
    "    print(\"Var explained:\", pca_explained_variance)\n",
    "    print(\"Sum var explained\", sum(pca_explained_variance))\n",
    "\n",
    "    # Save PCA Object\n",
    "    obj = pca\n",
    "    filename = \"PCA_\"+hex_size+\".pkl\"\n",
    "    pickle.dump(obj, open(os.path.join(os.getcwd(), \"..\", \"data\", \"output\", \"models\", filename), \"wb\"))\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var explained: [0.15560352 0.09140724 0.07950929 0.0733999  0.0623005  0.05947976\n",
      " 0.05766186 0.05259631 0.05043798 0.03771906 0.03316113 0.03097287\n",
      " 0.02952632 0.02920924 0.02806611 0.02678348 0.01816865 0.01684764\n",
      " 0.01490609 0.01442226]\n",
      "Sum var explained 0.9621791970573459\n",
      "Done\n",
      "Var explained: [0.15561609 0.09160127 0.07946086 0.07339026 0.06228626 0.05945796\n",
      " 0.05786381 0.05259267 0.05035591 0.03772232 0.0325973  0.03094871\n",
      " 0.02984517 0.02921511 0.02777875 0.02696405 0.01829781 0.01687906\n",
      " 0.01489943 0.01444143]\n",
      "Sum var explained 0.9622142312103297\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hex_sizes = [\"hexa_small\", \"hexa_big\"]\n",
    "for size in hex_sizes:\n",
    "    train_scaler_pca(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
