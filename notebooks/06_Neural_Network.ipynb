{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "A neural network is created which can be used for training and testing on trips data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (49.1.0.post20200704)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.20.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output=os.path.join(os.getcwd(), \"..\", \"data\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(os.path.join(path_output, \"Features.csv\"))\n",
    "features = features.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Params from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(os.path.join(os.getcwd(), \"..\", \"data\", \"input\", \"params.csv\")).drop(\"0\", axis=1)\n",
    "_test_size = params[params[\"param\"]==\"test_size\"][\"value\"].values[0]\n",
    "_random_state = int(params[params[\"param\"]==\"random_state\"][\"value\"].values[0])\n",
    "_epochs = int(params[params[\"param\"]==\"epochs\"][\"value\"].values[0])\n",
    "_validation_size = params[params[\"param\"]==\"validation_size\"][\"value\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X_train_scaled, y_train, on, hex_size):\n",
    "    \"\"\"\n",
    "    Train Neural Network Model\n",
    "\n",
    "    Train and save a Neural Network model.\n",
    "    The network has the following properties:\n",
    "        - three hidden layer\n",
    "        - 50 epochs\n",
    "        - activation function is relu\n",
    "        - dimension of input and hidden layer is 36\n",
    "        - dimension of output layer is 1\n",
    "        - dropout is not used\n",
    "    Then evaluate the error metrics by another method.\n",
    "\n",
    "    Args:\n",
    "        X_train_scaled (DataFrame):   Scaled X input of train set (matrix)\n",
    "        y_train (Series):             y output to train on (vector)\n",
    "    Returns:\n",
    "        nn_regression_sets (array): true y values and predicted y values for train and validation set\n",
    "    \"\"\"\n",
    "    # create a validation set which is 20% of the whole dataset. Therefore use formula to receive ca. 0.2857.\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, random_state=_random_state, test_size=_validation_size)\n",
    "    neural_network = keras.Sequential(\n",
    "        [layers.Dense(36, activation=\"relu\", input_shape=[X_train_scaled.shape[1]], kernel_initializer=\"random_normal\"),\n",
    "         # layers.Dropout(0.2),\n",
    "         layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         # layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         # layers.Dense(36, activation=\"relu\", kernel_initializer=\"random_normal\"),\n",
    "         # layers.Dense(36, activation=\"softmax\"),\n",
    "         # layers.Dense(36, activation=\"softmax\"),\n",
    "         # layers.Dropout(0.2),\n",
    "         layers.Dense(1)])\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "    neural_network.compile(loss=\"mse\",\n",
    "                           optimizer=optimizer,\n",
    "                           metrics=[\"mae\", \"mse\"])\n",
    "    epochs = _epochs\n",
    "    # create a validation set which is 20% of the whole dataset. Therefore use formula to receive ca. 0.2857.\n",
    "    history = neural_network.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
    "    neural_network.save(os.path.join(path_output, \"models\", \"NN_Regression_Model_\"+on+\"_\"+hex_size))\n",
    "    y_prediction_train = neural_network.predict(X_train)\n",
    "    y_prediction_val = neural_network.predict(X_val)\n",
    "    \n",
    "    r2_train = r2_score(y_train, y_prediction_train)\n",
    "    print(\"R2 (Train):\",r2_train)\n",
    "    r2_val = r2_score(y_val, y_prediction_val)\n",
    "    print(\"R2 (Validation):\",r2_val)\n",
    "    \n",
    "    plot_train_loss(history, on=on, hex_size=hex_size)\n",
    "    nn_regression_sets = [y_train, y_val, y_prediction_train, y_prediction_val]\n",
    "    return nn_regression_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss visualization by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss(history, on, hex_size):\n",
    "    \"\"\"\n",
    "    Plot the train and validation loss of Neural Network.\n",
    "\n",
    "    Args:\n",
    "        history (Object): History of loss during training of neural network\n",
    "        on (str): time resolution to train on\n",
    "    Returns:\n",
    "        No return\n",
    "    \"\"\"\n",
    "    print(\"Plot training and visualization loss...\")\n",
    "    # Plotting the training and validation loss\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=300)\n",
    "    ax.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    ax.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    ax.set_title(\"Training and validation loss \"+on+\"_\"+hex_size, fontsize=18)\n",
    "    ax.set_xlabel(\"Epochs\", fontsize=16)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=16)\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    fig.savefig(os.path.join(path_output, \"NN_error_per_epoch_\"+on+\"_\"+hex_size+\".png\"))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_NN(on=\"24_demand\", hex_size=\"hexa_big\"):\n",
    "    \"\"\"\n",
    "    Split the data in train and test set by 0.3 test set. \n",
    "    Then Scale the data and do a PCA. \n",
    "    Last train the NN on the chosen time resolution\n",
    "    \n",
    "    Args:\n",
    "        on (str): time resolution to train on\n",
    "        \n",
    "    Returns:\n",
    "        No return\n",
    "    \"\"\"\n",
    "    print(\"Time Resolution is\", on)\n",
    "    #print(\"Split Data with random state\", _random_state, \"and test size\", str(_test_size)+\"...\")\n",
    "    # features_X = features.drop([\"24_sum\", \"6_sum\", \"2_sum\", \"1_sum\"], axis=1)\n",
    "    features_X = features.drop([\"24_demand\", \"24_demand_hex_big\", \"24_demand_hex_small\", \"24_agg_time\",\n",
    "                                \"6_demand\", \"6_demand_hex_big\", \"6_demand_hex_small\", \"6_agg_time\",\n",
    "                                \"2_demand\", \"2_demand_hex_big\", \"2_demand_hex_small\", \"2_agg_time\",\n",
    "                                \"1_demand\", \"1_demand_hex_big\", \"1_demand_hex_small\", \"1_agg_time\"], axis=1)\n",
    "    features_y = features[on]\n",
    "    \n",
    "    # Spatial Resolution\n",
    "    print(\"Spatial Resolution is\", hex_size)\n",
    "    if hex_size==\"hexa_small\":\n",
    "        features_X = features_X.drop(\"hexa_big\", axis=1)\n",
    "    else:\n",
    "        features_X = features_X.drop(\"hexa_small\", axis=1)\n",
    "    \n",
    "    #Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_X, features_y, random_state=_random_state, test_size=_test_size)\n",
    "\n",
    "    #print(\"Scale\", hex_size, \"Data with Standard Scaler...\")\n",
    "    with open(os.path.join(path_output, \"models\", \"Standard_Scaler_\"+hex_size+\".pkl\"), \"rb\") as f:\n",
    "        standard_scaler = pickle.load(f)\n",
    "    X_train_scaled = standard_scaler.transform(X_train)\n",
    "\n",
    "    #print(\"Do PCA on\", hex_size, \"Data...\")\n",
    "    with open(os.path.join(path_output, \"models\", \"PCA_\"+hex_size+\".pkl\"), \"rb\") as f:\n",
    "        pca = pickle.load(f)\n",
    "    X_train_transformed = pca.transform(X_train_scaled)\n",
    "\n",
    "    print(\"Train\", \"NN_Regression_Model_\"+on+\"_\"+hex_size, \"...\")\n",
    "    nn_regression_sets = train_neural_network(X_train_transformed, y_train.to_numpy(), on=on, hex_size=hex_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Resolution is 24_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Train NN_Regression_Model_24_demand_hexa_small ...\n",
      "Epoch 1/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 976930.2500 - mae: 596.0048 - mse: 976930.2500 - val_loss: 335846.0000 - val_mae: 393.0370 - val_mse: 335846.0000\n",
      "Epoch 2/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 219402.6094 - mae: 324.0703 - mse: 219402.6094 - val_loss: 190003.1094 - val_mae: 308.3834 - val_mse: 190003.1094\n",
      "Epoch 3/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 164518.1562 - mae: 267.0937 - mse: 164518.1562 - val_loss: 130616.1562 - val_mae: 250.2670 - val_mse: 130616.1562\n",
      "Epoch 4/20\n",
      "8867/8867 [==============================] - 13s 2ms/step - loss: 106881.8516 - mae: 222.0331 - mse: 106881.8516 - val_loss: 96479.1016 - val_mae: 205.7475 - val_mse: 96479.1016\n",
      "Epoch 5/20\n",
      "8867/8867 [==============================] - 19s 2ms/step - loss: 84579.5234 - mae: 190.8629 - mse: 84579.5234 - val_loss: 100207.8906 - val_mae: 201.6864 - val_mse: 100207.8906\n",
      "Epoch 6/20\n",
      "8867/8867 [==============================] - 18s 2ms/step - loss: 65914.8828 - mae: 168.8486 - mse: 65914.8828 - val_loss: 67617.5547 - val_mae: 173.0680 - val_mse: 67617.5547\n",
      "Epoch 7/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 53497.8906 - mae: 152.4988 - mse: 53497.8906 - val_loss: 64236.3828 - val_mae: 185.8810 - val_mse: 64236.3828\n",
      "Epoch 8/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 44626.0391 - mae: 137.8686 - mse: 44626.0391 - val_loss: 40227.6484 - val_mae: 127.8115 - val_mse: 40227.6484\n",
      "Epoch 9/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 39036.7070 - mae: 125.9122 - mse: 39036.7070 - val_loss: 50929.0312 - val_mae: 140.8130 - val_mse: 50929.0312\n",
      "Epoch 10/20\n",
      "8867/8867 [==============================] - 16s 2ms/step - loss: 36478.2461 - mae: 117.1508 - mse: 36478.2461 - val_loss: 36937.6602 - val_mae: 123.9243 - val_mse: 36937.6602\n",
      "Epoch 11/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 35757.0781 - mae: 110.3372 - mse: 35757.0781 - val_loss: 39194.4023 - val_mae: 128.8696 - val_mse: 39194.4023\n",
      "Epoch 12/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 27995.4922 - mae: 105.1578 - mse: 27995.4922 - val_loss: 28007.4238 - val_mae: 108.6411 - val_mse: 28007.4238\n",
      "Epoch 13/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 25329.9824 - mae: 100.3345 - mse: 25329.9824 - val_loss: 23952.0273 - val_mae: 100.3306 - val_mse: 23952.0273\n",
      "Epoch 14/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 24110.4551 - mae: 95.6854 - mse: 24110.4551 - val_loss: 27590.6133 - val_mae: 109.6357 - val_mse: 27590.6133\n",
      "Epoch 15/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 21526.6152 - mae: 92.2833 - mse: 21526.6152 - val_loss: 21788.5234 - val_mae: 89.8480 - val_mse: 21788.5234\n",
      "Epoch 16/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 20514.2207 - mae: 89.3996 - mse: 20514.2207 - val_loss: 17374.9863 - val_mae: 83.1038 - val_mse: 17374.9863\n",
      "Epoch 17/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 18948.9512 - mae: 86.0287 - mse: 18948.9512 - val_loss: 17447.1309 - val_mae: 75.1542 - val_mse: 17447.1309\n",
      "Epoch 18/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 20078.3223 - mae: 82.7899 - mse: 20078.3223 - val_loss: 15820.1182 - val_mae: 81.0682 - val_mse: 15820.1182\n",
      "Epoch 19/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 16888.7188 - mae: 80.3459 - mse: 16888.7188 - val_loss: 29992.9941 - val_mae: 128.6099 - val_mse: 29992.9941\n",
      "Epoch 20/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 16532.2129 - mae: 77.4980 - mse: 16532.2129 - val_loss: 12165.0010 - val_mae: 69.7644 - val_mse: 12165.0010\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/work/notebooks/../data/output/models/NN_Regression_Model_24_demand_hexa_small/assets\n",
      "R2 (Train): 0.9945038404625828\n",
      "R2 (Validation): 0.9947663193083556\n",
      "Plot training and visualization loss...\n",
      "\n",
      "Time Resolution is 6_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Train NN_Regression_Model_6_demand_hexa_small ...\n",
      "Epoch 1/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 480441.5938 - mae: 361.0285 - mse: 480441.5938 - val_loss: 185262.7188 - val_mae: 266.2648 - val_mse: 185262.7188\n",
      "Epoch 2/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 127582.4219 - mae: 224.6650 - mse: 127582.4219 - val_loss: 97714.4062 - val_mae: 197.6998 - val_mse: 97714.4062\n",
      "Epoch 3/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 298984.0938 - mae: 191.8842 - mse: 298984.0938 - val_loss: 88416.2031 - val_mae: 182.6481 - val_mse: 88416.2031\n",
      "Epoch 4/20\n",
      "8867/8867 [==============================] - 16s 2ms/step - loss: 207280.0000 - mae: 163.8847 - mse: 207280.0000 - val_loss: 81546.8828 - val_mae: 165.7624 - val_mse: 81546.8828\n",
      "Epoch 5/20\n",
      "8867/8867 [==============================] - 16s 2ms/step - loss: 64326.3242 - mae: 144.4296 - mse: 64326.3242 - val_loss: 61814.4844 - val_mae: 145.5063 - val_mse: 61814.4844\n",
      "Epoch 6/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 73691.5312 - mae: 133.4288 - mse: 73691.5312 - val_loss: 46946.0430 - val_mae: 127.5042 - val_mse: 46946.0430\n",
      "Epoch 7/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 49750.4453 - mae: 125.2167 - mse: 49750.4453 - val_loss: 48820.7578 - val_mae: 130.1857 - val_mse: 48820.7578\n",
      "Epoch 8/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 55595.7656 - mae: 119.1392 - mse: 55595.7656 - val_loss: 38552.0312 - val_mae: 113.0784 - val_mse: 38552.0312\n",
      "Epoch 9/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 42653.7617 - mae: 112.7861 - mse: 42653.7617 - val_loss: 43958.1367 - val_mae: 119.6399 - val_mse: 43958.1367\n",
      "Epoch 10/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 49627.0859 - mae: 108.1916 - mse: 49627.0859 - val_loss: 41741.3008 - val_mae: 107.7142 - val_mse: 41741.3008\n",
      "Epoch 11/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 39057.6328 - mae: 103.9465 - mse: 39057.6328 - val_loss: 34812.9805 - val_mae: 97.3175 - val_mse: 34812.9805\n",
      "Epoch 12/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 38119.8633 - mae: 101.3056 - mse: 38119.8633 - val_loss: 48445.4570 - val_mae: 114.3698 - val_mse: 48445.4570\n",
      "Epoch 13/20\n",
      "8867/8867 [==============================] - 16s 2ms/step - loss: 36394.6484 - mae: 98.3852 - mse: 36394.6484 - val_loss: 34879.0625 - val_mae: 107.5486 - val_mse: 34879.0625\n",
      "Epoch 14/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 34414.2070 - mae: 95.2342 - mse: 34414.2070 - val_loss: 30447.9180 - val_mae: 99.5122 - val_mse: 30447.9180\n",
      "Epoch 15/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 34302.2500 - mae: 92.5981 - mse: 34302.2500 - val_loss: 42720.6328 - val_mae: 93.3851 - val_mse: 42720.6328\n",
      "Epoch 16/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 32936.5938 - mae: 90.7468 - mse: 32936.5938 - val_loss: 41571.2578 - val_mae: 92.9753 - val_mse: 41571.2578\n",
      "Epoch 17/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 33271.7539 - mae: 89.0224 - mse: 33271.7539 - val_loss: 42037.0430 - val_mae: 90.5845 - val_mse: 42037.0430\n",
      "Epoch 18/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 32120.9785 - mae: 86.9804 - mse: 32120.9785 - val_loss: 29264.5254 - val_mae: 87.3366 - val_mse: 29264.5254\n",
      "Epoch 19/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 31808.5254 - mae: 86.3419 - mse: 31808.5254 - val_loss: 24292.7617 - val_mae: 89.3465 - val_mse: 24292.7617\n",
      "Epoch 20/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 30404.9746 - mae: 84.6518 - mse: 30404.9746 - val_loss: 29968.2598 - val_mae: 89.7953 - val_mse: 29968.2598\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/work/notebooks/../data/output/models/NN_Regression_Model_6_demand_hexa_small/assets\n",
      "R2 (Train): 0.9704294277941219\n",
      "R2 (Validation): 0.9722843448088709\n",
      "Plot training and visualization loss...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Resolution is 2_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Train NN_Regression_Model_2_demand_hexa_small ...\n",
      "Epoch 1/20\n",
      "8867/8867 [==============================] - 20s 2ms/step - loss: 105633.1875 - mae: 199.5388 - mse: 105633.1875 - val_loss: 55951.0156 - val_mae: 160.6839 - val_mse: 55951.0156\n",
      "Epoch 2/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 45558.5898 - mae: 142.4267 - mse: 45558.5898 - val_loss: 35591.8359 - val_mae: 122.0341 - val_mse: 35591.8359\n",
      "Epoch 3/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 32998.6016 - mae: 120.1759 - mse: 32998.6016 - val_loss: 27957.4473 - val_mae: 110.0254 - val_mse: 27957.4473\n",
      "Epoch 4/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 27100.9746 - mae: 106.9056 - mse: 27100.9746 - val_loss: 25229.8789 - val_mae: 100.9622 - val_mse: 25229.8789\n",
      "Epoch 5/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 22492.1602 - mae: 95.9318 - mse: 22492.1602 - val_loss: 20999.1230 - val_mae: 89.9945 - val_mse: 20999.1230\n",
      "Epoch 6/20\n",
      "8867/8867 [==============================] - 13s 2ms/step - loss: 19374.8906 - mae: 87.9145 - mse: 19374.8906 - val_loss: 26362.9902 - val_mae: 96.3450 - val_mse: 26362.9902\n",
      "Epoch 7/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 17340.1738 - mae: 81.4420 - mse: 17340.1738 - val_loss: 20855.1016 - val_mae: 83.1749 - val_mse: 20855.1016\n",
      "Epoch 8/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 15502.8613 - mae: 76.2238 - mse: 15502.8613 - val_loss: 14742.0039 - val_mae: 73.1625 - val_mse: 14742.0039\n",
      "Epoch 9/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 13894.7969 - mae: 72.1305 - mse: 13894.7969 - val_loss: 16133.4941 - val_mae: 73.6068 - val_mse: 16133.4941\n",
      "Epoch 10/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 12860.8428 - mae: 68.7154 - mse: 12860.8428 - val_loss: 14719.5840 - val_mae: 71.1340 - val_mse: 14719.5840\n",
      "Epoch 11/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 12269.6641 - mae: 66.3075 - mse: 12269.6641 - val_loss: 12887.1279 - val_mae: 67.8402 - val_mse: 12887.1279\n",
      "Epoch 12/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 11490.1924 - mae: 63.8001 - mse: 11490.1924 - val_loss: 13058.6182 - val_mae: 66.7211 - val_mse: 13058.6182\n",
      "Epoch 13/20\n",
      "8867/8867 [==============================] - 16s 2ms/step - loss: 10980.4590 - mae: 61.5042 - mse: 10980.4590 - val_loss: 10662.9873 - val_mae: 59.8467 - val_mse: 10662.9873\n",
      "Epoch 14/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 10399.1592 - mae: 59.2741 - mse: 10399.1592 - val_loss: 10471.3838 - val_mae: 57.6029 - val_mse: 10471.3838\n",
      "Epoch 15/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 9957.1689 - mae: 57.8105 - mse: 9957.1689 - val_loss: 14131.4912 - val_mae: 67.0274 - val_mse: 14131.4912\n",
      "Epoch 16/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 9617.5439 - mae: 56.5603 - mse: 9617.5439 - val_loss: 10132.9658 - val_mae: 56.1352 - val_mse: 10132.9658\n",
      "Epoch 17/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 9218.3457 - mae: 55.3738 - mse: 9218.3457 - val_loss: 11174.2959 - val_mae: 60.3913 - val_mse: 11174.2959\n",
      "Epoch 18/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 8938.1533 - mae: 54.3115 - mse: 8938.1533 - val_loss: 13169.9316 - val_mae: 58.2588 - val_mse: 13169.9316\n",
      "Epoch 19/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 8656.5400 - mae: 53.2619 - mse: 8656.5400 - val_loss: 10061.9795 - val_mae: 58.4733 - val_mse: 10061.9795\n",
      "Epoch 20/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 8465.5605 - mae: 52.2440 - mse: 8465.5605 - val_loss: 8715.0801 - val_mae: 52.4245 - val_mse: 8715.0801\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/work/notebooks/../data/output/models/NN_Regression_Model_2_demand_hexa_small/assets\n",
      "R2 (Train): 0.9714759235124876\n",
      "R2 (Validation): 0.9688034647214451\n",
      "Plot training and visualization loss...\n",
      "\n",
      "Time Resolution is 1_demand\n",
      "Spatial Resolution is hexa_small\n",
      "Train NN_Regression_Model_1_demand_hexa_small ...\n",
      "Epoch 1/20\n",
      "8867/8867 [==============================] - 13s 2ms/step - loss: 59088.1328 - mae: 158.6883 - mse: 59088.1328 - val_loss: 34203.1875 - val_mae: 129.9536 - val_mse: 34203.1875\n",
      "Epoch 2/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 30553.5000 - mae: 119.4519 - mse: 30553.5000 - val_loss: 27749.5293 - val_mae: 108.9073 - val_mse: 27749.5293\n",
      "Epoch 3/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 24799.6816 - mae: 104.9261 - mse: 24799.6816 - val_loss: 23626.8477 - val_mae: 108.8075 - val_mse: 23626.8477\n",
      "Epoch 4/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 20640.5000 - mae: 93.0290 - mse: 20640.5000 - val_loss: 18806.5312 - val_mae: 87.5746 - val_mse: 18806.5312\n",
      "Epoch 5/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 17746.1602 - mae: 82.8833 - mse: 17746.1602 - val_loss: 17250.1074 - val_mae: 81.1634 - val_mse: 17250.1074\n",
      "Epoch 6/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 15405.6201 - mae: 74.6227 - mse: 15405.6201 - val_loss: 14115.8809 - val_mae: 71.3711 - val_mse: 14115.8809\n",
      "Epoch 7/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 13692.2578 - mae: 68.9330 - mse: 13692.2578 - val_loss: 13444.1494 - val_mae: 68.1811 - val_mse: 13444.1494\n",
      "Epoch 8/20\n",
      "8867/8867 [==============================] - 13s 1ms/step - loss: 12082.7471 - mae: 63.7686 - mse: 12082.7471 - val_loss: 10979.1289 - val_mae: 60.5218 - val_mse: 10979.1289\n",
      "Epoch 9/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 10892.5781 - mae: 59.9298 - mse: 10892.5781 - val_loss: 9878.2676 - val_mae: 57.3314 - val_mse: 9878.2676\n",
      "Epoch 10/20\n",
      "8867/8867 [==============================] - 13s 1ms/step - loss: 9961.3779 - mae: 56.7705 - mse: 9961.3779 - val_loss: 9198.8164 - val_mae: 53.6852 - val_mse: 9198.8164\n",
      "Epoch 11/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 9298.8447 - mae: 54.0359 - mse: 9298.8447 - val_loss: 8983.3604 - val_mae: 51.3596 - val_mse: 8983.3604\n",
      "Epoch 12/20\n",
      "8867/8867 [==============================] - 15s 2ms/step - loss: 8899.5049 - mae: 52.2303 - mse: 8899.5049 - val_loss: 8858.6279 - val_mae: 52.5296 - val_mse: 8858.6279\n",
      "Epoch 13/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 8459.9229 - mae: 50.4574 - mse: 8459.9229 - val_loss: 8152.6548 - val_mae: 50.9106 - val_mse: 8152.6548\n",
      "Epoch 14/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 8056.4556 - mae: 48.8910 - mse: 8056.4556 - val_loss: 9102.6016 - val_mae: 49.5459 - val_mse: 9102.6016\n",
      "Epoch 15/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 7672.5947 - mae: 47.2139 - mse: 7672.5947 - val_loss: 6896.4907 - val_mae: 43.4616 - val_mse: 6896.4907\n",
      "Epoch 16/20\n",
      "8867/8867 [==============================] - 14s 2ms/step - loss: 7366.2949 - mae: 45.9749 - mse: 7366.2949 - val_loss: 8430.8154 - val_mae: 48.7923 - val_mse: 8430.8154\n",
      "Epoch 17/20\n",
      "8867/8867 [==============================] - 19s 2ms/step - loss: 7020.6641 - mae: 44.6632 - mse: 7020.6641 - val_loss: 7061.2891 - val_mae: 45.6145 - val_mse: 7061.2891\n",
      "Epoch 18/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 6837.0308 - mae: 43.9375 - mse: 6837.0308 - val_loss: 6126.8911 - val_mae: 42.0328 - val_mse: 6126.8911\n",
      "Epoch 19/20\n",
      "8867/8867 [==============================] - 17s 2ms/step - loss: 6508.6001 - mae: 42.5546 - mse: 6508.6001 - val_loss: 5795.1011 - val_mae: 39.2827 - val_mse: 5795.1011\n",
      "Epoch 20/20\n",
      "8867/8867 [==============================] - 16s 2ms/step - loss: 6332.3735 - mae: 41.8422 - mse: 6332.3735 - val_loss: 7168.0767 - val_mae: 45.4249 - val_mse: 7168.0767\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/work/notebooks/../data/output/models/NN_Regression_Model_1_demand_hexa_small/assets\n",
      "R2 (Train): 0.9354454820217214\n",
      "R2 (Validation): 0.9330963090448678\n",
      "Plot training and visualization loss...\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Train the NN for each time resolution.\n",
    "# hex_size = [\"hexa_small\", \"hexa_big\"]\n",
    "hex_size = [\"hexa_big\", \"hexa_small\"]\n",
    "time_resolutions = [\"24_demand\", \"6_demand\", \"2_demand\", \"1_demand\"]\n",
    "for time in time_resolutions:\n",
    "    for size in hex_size:\n",
    "        train_NN(on=time, hex_size=size)\n",
    "        print()\n",
    "print(\"Done\")\n",
    "#train_NN(on=\"1_sum\", hex_size=\"hexa_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
